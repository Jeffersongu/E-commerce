{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQCCki/2K1dbR6x9T2RgPc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeffersongu/E-commerce/blob/main/Ingest%C3%A3o_de_Dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPY69QwJd8i2"
      },
      "outputs": [],
      "source": [
        "# Ingestão de Dados.\n",
        "# Objetivo: Extrair o arquivo preco_competidores no formato parquet do DataLake do Supabe Storage."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guia do Desenvolvedor:\n",
        "https://aws.amazon.com/pt/sdk-for-python/\n",
        "\n",
        "# Acesse em Recuros adicionais o Guia do Desenvolvedor:\n",
        "https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html\n",
        "\n",
        "# Code Exemples/ Amazon S3 examples/ Downloading files:\n",
        "https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-download-file.html\n"
      ],
      "metadata": {
        "id": "Pw2KQTLIscUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conectar com DataLake e Ler Parquet\n",
        "# Instalando a biblioteca Boto3, é responsável por dar acesso ao S3\n",
        "\n",
        "!pip install boto3"
      ],
      "metadata": {
        "id": "Mkcrj8nmncj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca, vamos pegar o arquivo parquet e colocar dentro do google colab:\n",
        "\n",
        "import boto3"
      ],
      "metadata": {
        "id": "V9OonABqYUEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurações do DataLake:\n",
        "# Acesse: Supabase/ Storage/ datalake/ S3/ Copie e cole nas variáveis\n",
        "# Gerando uma chave de acesso: New access key/ Descryption chave_acesso/ create key/ Copie e cole nas variáveis\n",
        "# Bucket name é o nome do seu data Lake\n",
        "\n",
        "S3_ENDPOINT_URL = \"https://vvkwfsdbckdzwsciplct.storage.supabase.co/storage/v1/s3\"\n",
        "AWS_REGION = \"us-east-1\"\n",
        "AWS_ACCESS_KEY_ID = \"ada9f04a035ab5eaa7f19bfdc58ee5a2\"\n",
        "AWS_SECRET_ACCESS_KEY = \"21753b37aa16dc146add390bfc0b1705d6a6523bd90577cdec84af8fbcbe5f84\"\n",
        "BUCKET_NAME = \"datalake\"\n"
      ],
      "metadata": {
        "id": "17q9fRwAtDGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar a variável cliente S3 utilizando a biblioteca boto3;\n",
        "# Abaixo passamos as variáveis que declaramos no código acima;\n",
        "# Isso permite que logamos na instância do S3 com o código python:\n",
        "\n",
        "s3 = boto3.client(\n",
        "    \"s3\",\n",
        "    region_name=AWS_REGION,\n",
        "    endpoint_url=S3_ENDPOINT_URL,\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "AvcI0c9kYMiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listar arquivos no bucket:\n",
        "\n",
        "response = s3.list_objects(Bucket=BUCKET_NAME)\n",
        "arquivos = [obj[\"Key\"] for obj in response[\"Contents\"]]\n",
        "\n",
        "print(arquivos)"
      ],
      "metadata": {
        "id": "QNs-RBGPdSvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trabalhando com o arquivo parquet, manipulando dados com a biblioteca Pandas:\n",
        "\n",
        "# Instalar pandas: pip install pandas pyarrow\n",
        "import pandas as pd\n",
        "\n",
        "# Trabalha com dados \"em memória\" transforma um bytes\n",
        "import io"
      ],
      "metadata": {
        "id": "K79qbZ9dd-9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar arquivo Parquet:\n",
        "\n",
        "FILE_KEY = \"preco_competidores.parquet\"\n",
        "response = s3.get_object(Bucket=BUCKET_NAME, Key=FILE_KEY)\n",
        "parquet_bytes = response[\"Body\"].read()"
      ],
      "metadata": {
        "id": "J3JXJ9f2fAHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter Parquet para DataFrame:\n",
        "# Dataframe dentro do python é um objeto apenas com estrutura de dados diferente, tem várias estrutura de dados como string, dicionário, S3 e dataframe...\n",
        "# Ele não é um dicionário ou uma table, ele é um dataframe com características de dados diferente.\n",
        "\n",
        "df_precos = pd.read_parquet(io.BytesIO(parquet_bytes))\n",
        "\n",
        "print(df_precos)"
      ],
      "metadata": {
        "id": "27R4rXRsif9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o tipo de dado:\n",
        "\n",
        "print(type(df_precos))"
      ],
      "metadata": {
        "id": "cJvqhir5Q2hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Qual a diferença entre um arquivo parquet e CSV?\n",
        "# O que diferencia estes dois formatos são a sua estrutura de dados, parquet é binário e o csv é texto."
      ],
      "metadata": {
        "id": "mPUuS-d1kJZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingestão de Dados.\n",
        "# Objetivo: Carregar o arquivo preco_competidores no formato dataframe  para o banco de dados ecommerce."
      ],
      "metadata": {
        "id": "ICRMoB5ZQoH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando a biblioteca Sqlalchemy:\n",
        "\n",
        "!pip install  sqlalchemy"
      ],
      "metadata": {
        "id": "gkyL3eeFX838"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando da biblioteca:\n",
        "# Permite trabalharmos com dados em SQL, vai nos permitir carregar o dataframe no banco de dados:\n",
        "\n",
        "from sqlalchemy import create_engine"
      ],
      "metadata": {
        "id": "MgPp68thW1hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscando as variáveis do banco de dados ecommerce;\n",
        "# Acesse o banco de dados ecommerce no Supabase/ Clique em connect/ Connection string/ Method selecione Session Pooler e copie view parameters\n",
        "# [YOUR-PASSWORD] neste local do código cole a senha do banco de dados, se for necessário reset a senha para obter uma nova!\n",
        "# Por segurança vou manter somente descrição [YOUR-PASSWORD].\n",
        "\n",
        "DATABASE_URL = \"postgresql://postgres.vvkwfsdbckdzwsciplct:[YOUR-PASSWORD]@aws-1-us-east-1.pooler.supabase.com:5432/postgres\""
      ],
      "metadata": {
        "id": "jx0O-63OYkKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma conexão com o banco de dados ecommerce:\n",
        "\n",
        "engine = create_engine(DATABASE_URL)"
      ],
      "metadata": {
        "id": "qU0kvrLEfEMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar DataFrame em tabela PostgreSQL\n",
        "# if_exists: 'replace' (substitui), 'append' (adiciona), 'fail' (erro se existir)\n",
        "\n",
        "df_precos.to_sql(\n",
        "    \"precos_processados\",  # Nome da tabela\n",
        "    engine,  # Engine de conexão\n",
        "    if_exists=\"replace\",  # Substituir se existir\n",
        "    index=False  # Não salvar índice\n",
        ")"
      ],
      "metadata": {
        "id": "29HyOuJHg_4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ler dados salvos para verificar:\n",
        "\n",
        "df_verificacao = pd.read_sql_query(\"SELECT * FROM precos_processados\", engine)\n",
        "\n",
        "print(df_verificacao)"
      ],
      "metadata": {
        "id": "PXbKKALHmf2L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}